\section{Experiments}
We conducted three series of experiments to test our new encoding: a correctness test on the running examples presented in this paper, a scalability test on the effects of message non-determinism, and a typical benchmark test on several programs. All the results show the comparison between the zero buffer encoding and the infinite buffer encoding.  Those experiments were run on a 2.40 GHz Intel Quad Core processor with 8 GB memory running Windows 7. We set a time limit of 2 hours for each test. We abort the verification process if it did not complete within the time limit. 

The initial program trace was generated by running MPICH \cite{mpich}, a publicly prevalent implementation of MPI standard, with fixed input. The experiments only considered one path of the control flow through the program. Complete coverage of the program for verification purposes would need to generate input to exercise different control flow paths. 

\begin{table*}[t]
\begin{center}
\scriptsize
\caption{Tests on Selected Benchmarks}\label{table:benchmarks}
\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
         \multicolumn{4}{|c|}{Test Programs} & \multicolumn{3}{|c|}{Performance} \\ \hline
          $Name$&\# Mesg&Matches&Buffering&Error&Time(hh:mm:ss)&Mem(MB) \\ \hline
           \textit{Matmat} & 11 & 1 & 0 & No & $<$00:00:01 & 2.60\\
          	      & & & $\infty$ & No & $<$00:00:01 & 2.58\\ \hline
	 \textit{Mento} & 49 & $\sim$6E27 & 0 & No & 00:00:02 & 21.52\\
          \textit{Carlo}  & & & $\infty$ & No & 00:00:03 & 17.29 \\ \hline
	 \textit{Router}   & 200 & $\sim$6E2 & 0 & -- & -- & --\\
          	      & & & $\infty$ & Yes & 00:00:02 & 17.07 \\ \hline
	 \textit{Integrate}  & 123 & $\sim$1E51 & 0 & No & 00:00:59 & 134.95 \\
          	      & & &  $\infty$ & No & 00:08:23 & 238.68\\ \hline
	  \textit{Diffusion}  & 54 & $\sim$5E57 & 0 & Yes & 00:00:11 & 52.54 \\
           \textit{2D} &  & & $\infty$ & Yes & 00:09:54 & 98.56\\ \hline          
          		\end{tabular}
\end{center}
\end{table*}

Given the boundary on match resolutions, we compare several benchmark programs to test our new encoding. The goal is to further understand how our encoding scales to those programs that are publicly available from a variety of sources. The results pertaining to the performance are documented in \tableref{table:benchmarks}. 

\begin{compactitem}

\item \textit{Mento Carlo} implements the Mento Carlo method to compute $\pi$ \cite{benchmark:mentoCarlo}. It uses one manger process and three worker processes to send messages back of forth. In addition, it frequently uses barrier operations in many places to synchronize the program. 
\item \textit{Router} is an algorithm to update routing tables for 50 nodes. Each node is in a ring and communicates only with immediate neighbors to update the tables. The program ends when all the routing tables are updated. 
\item \textit{Matmat} implements matrix multiplication \cite{benchmark:fevs}. It reads two matrices from the files and outputs their product. In this program, there are only two processes to communicate messages. The message size is also low.
\item \textit{Integrate} uses heavy non-determinism in message communication to compute an integral of $\sin$ function over the interval $[0, \pi]$ \cite{benchmark:fevs}. This benchmark also has a manger-worker pattern where the root process divides the interval in a certain number of tasks. It then distributes those tasks to three worker processes. %Each worker continues working on a task until it receives a termination message from the manger.
\item \textit{Diffusion 2D} has an interesting computation pattern that uses barriers to ``partition" the message communication into several sections for four processes \cite{benchmark:fevs}. A message from a send can only be received in a common section. 
\end{compactitem}

As before, we test both buffering settings for each benchmark program. The results show that the zero buffer encoding returns much faster than the infinite buffer encoding for all the benchmark programs. In particular, the test of \textit{Router} demonstrates that it is not compatible with zero buffer semantics. The size of match resolutions is still the primary measure of scalability. \textit{Matmat} is the easiest program to solve. This program has only a single match resolution for the SMT solver to consider thus returns quickly and uses little memory. The programs \textit{Mento Carlo}, \textit{Router}, \textit{Integrate} and \textit{Diffusion 2D} respectively increase the size of match resolutions. For example, even though \textit{Router} has 200 messages, it has less choices of match resolutions thus returns faster than \textit{Integrate} and \textit{Diffusion 2D}. 

The benchmark suite demonstrates that an MPI program may have a large degree of message non-determinism in runtime. The number of match resolutions is the only deciding factor in scalability of our encoding. For example, even though \textit{Integrate} has more messages than the scalability test with 80 messages, it has less choices for resolving send-receive matches. Therefore, it can be solved with reasonable runtime. As such, the benchmark suite suggests that a program is able to complete in a reasonable amount of time if the number of match resolutions is under the boundary obtained in our scalability test.
