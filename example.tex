\section{Example}\label{sec:example}
\subsection{Point-To-Point Communication}
It is worthwhile to take a look at a simple scenario with several MPI calls. Consider \figref{fig:mpi} as an example, it is a trace program including point-to-point operations, i.e., sends and receives, for message communication. Branch and loop structures are not included because the program itself is generated by an execution trace. The notation ``\texttt{---}" represents the operations ``\texttt{MPI\_Init}" and ``\texttt{MPI\_Finalize}" that are necessary but not interesting in our discussion. The shorthand notations are used in this program. To be precise, $\mathtt{S}$ represents a non-blocking send; $\mathtt{R}$ represents a non-blocking receive; and $\mathtt{W}$ represents a wait for a send or a receive. For this MPI scenario, line \texttt{00} and \texttt{02} on process $0$ receives two messages in variables $A$ and $B$,respectively; line \texttt{10} on Process $1$ receives a message in variable $C$ from process $2$ and then sends a message ``\texttt{1}" at line \texttt{12} to process $0$; and line \texttt{20} and \texttt{22} on process $2$ sends a message ``\texttt{4}" and ``\texttt{Go}" to process $0$ and $1$, respectively. In addition, process $0$ asserts that variable $A$ is equal to ``\texttt{4}" at line \texttt{04}. The wait operations witness the completion of the associated sends or receives meaning the buffer is free to be reused. Each receive on process $0$ may receive a message from any source, specified in the parameter ``from", thus is called a wildcard receive. The receive on process $1$ specifies a explicit source thus is called a deterministic receive. \textit{Given this scenario, is variable $A$ assigned a corresponding value in all possible executions so the property on process $0$ does not fail?}

%\subsection{Outcoming Traces}
\begin{figure}[b]
\begin{center}
\setlength{\tabcolsep}{2pt}
\small \begin{tabular}[t]{l}
20 $\mathtt{S(to\ P0, "4", \&h5)}$ \\
21 $\mathtt{W(\&h5)}$\\
\hline
00 $\mathtt{R(from\ P2, A, \&h1)}$ \\
01 $\mathtt{W(\&h1)}$ \\
\hline
22 $\mathtt{S(to\ P1, "Go", \&h6)}$ \\
23 $\mathtt{W(\&h6)}$ \\
\hline
10 $\mathtt{R(from\ P2, C, \&h3)}$ \\
11 $\mathtt{W(\&h3)}$ \\
12 $\mathtt{S(to\ P0, "1", \&h4)}$ \\
13 $\mathtt{W(\&h4)}$ \\
\hline
02 $\mathtt{R(from\ P1, B, \&h2)}$ \\
03 $\mathtt{W(\&h2)}$ \\
04 $\mathtt{assume(B > 0)}$
05 $\mathtt{assert(A == 4)}$ \\
\hline
\end{tabular}
\end{center}
\caption{A feasible execution trace of the MPI program execution in \figref{fig:mpi}}
\label{fig:trace1}
\end{figure}

\figref{fig:trace1} is a feasible execution of the events in \figref{fig:mpi}. The source parameter in each wildcard receive is replaced with a explicit process rank indicating each message is deterministically delivered. In this trace, process $2$ first sends the message ``\texttt{4}" which is immediately received by process $0$ in variable $A$. Process $2$ then sends another message ``\texttt{Go}" which is received by process $1$ in variable $C$. After the receive on process $1$ is completed, the send at line \texttt{12} is able to be issued. Finally, the message ``\texttt{1}" is received by process $0$ in variable $B$. The control flow that ``\texttt{B > 0}" is captured and the assert at line \texttt{05} does not fail. As shown in the trace, each message is immediately received by a matching receive. This communication topology is enforced by a zero-buffering semantic, but is not required by a infinite-buffering semantic.

\begin{figure}[t]
\begin{center}
\setlength{\tabcolsep}{2pt}
\small \begin{tabular}[t]{l}
20 $\mathtt{S(to\ P0, "4", \&h5)}$ \\
21 $\mathtt{W(\&h5)}$\\
22 $\mathtt{S(to\ P1, "Go", \&h6)}$ \\
23 $\mathtt{W(\&h6)}$ \\
\hline
10 $\mathtt{R(from\ P2, C, \&h3)}$ \\
11 $\mathtt{W(\&h3)}$ \\
12 $\mathtt{S(to\ P0, "1", \&h4)}$ \\
13 $\mathtt{W(\&h4)}$ \\
\hline
00 $\mathtt{R(from\ P1, A, \&h1)}$ \\
01 $\mathtt{W(\&h1)}$ \\
02 $\mathtt{R(from\ P2, B, \&h2)}$ \\
03 $\mathtt{W(\&h2)}$ \\
04 $\mathtt{assume(B > 0)}$
05 $\mathtt{assert(A == 4)}$ \\
\hline
\end{tabular}
\end{center}
\caption{A second feasible execution trace of the MPI program execution in \figref{fig:mpi}}
\label{fig:trace2}
\end{figure}

It is possible to execute the same program with another feasible trace (\figref{fig:trace2}). This trace assumes a infinite-buffer setting is implemented in the runtime environment. Unlike the first trace, \figref{fig:trace2} buffers the message ``4" instead of transferring it immediately. The message ``\texttt{Go}" is then sent from process $2$ to process $1$ in variable $C$. After that, the message ``1" on process $1$ is sent out. At this point, the arrival of message ``4" and ``1" are racing and the message ``1" arrives first. As a result, variable $A$ is equal to ``\texttt{1}" and the assertion at line \texttt{04} fails.

As shown in both traces, the message non-determinism is essential to testing and debugging an MPI program, especially when infinite-buffering is implemented which provides more flexibility for message passing. Observe that \figref{fig:trace2} can only occur under a infinite buffer setting. If a zero buffer setting is implemented, the message ``\texttt{4}" must be received immediately in variable $A$ by process $0$ once it is sent out. Therefore, the assert at line \texttt{04} should not fail under zero-buffering. 

%:TODO describe two traces 
%:TODO describe what happened if the messages are not buffered.

\subsection{Collective Communication}
Consider the collective operations such as barriers, the MPI semantics can be more difficult to analyze. \figref{fig:mpi_barrier} refines the program in \figref{fig:mpi} by inserting a barrier (underlined) on each process. Each barrier is specified by a group identity, i.e., ``\texttt{comm}", and blocks the execution on each process unless all the barriers are witnessed. \textit{Given this scenario, does the assert on process $0$ fail assuming the infinite-buffering is provided?}

\examplefigoneB

\begin{figure}[c]
\begin{center}
\setlength{\tabcolsep}{2pt}
\small \begin{tabular}[t]{l}
20 $\mathtt{S(to\ P0, "4", \&h5)}$ \\
21 $\mathtt{W(\&h5)}$\\
22 $\mathtt{\underline{B(comm)}}$\\
\hline
10 $\mathtt{\underline{B(comm)}}$\\
\hline
00 $\mathtt{R(from\ P2, A, \&h1)}$ \\
01 $\mathtt{W(\&h1)}$ \\
02 $\mathtt{\underline{B(comm)}}$\\
\hline
23 $\mathtt{S(to\ P1, "Go", \&h6)}$ \\
24 $\mathtt{W(\&h6)}$ \\
\hline
11 $\mathtt{R(from\ P2, C, \&h3)}$ \\
12 $\mathtt{W(\&h3)}$ \\
13 $\mathtt{S(to\ P0, "1", \&h4)}$ \\
14 $\mathtt{W(\&h4)}$ \\
\hline
03 $\mathtt{R(from\ P1, B, \&h2)}$ \\
04 $\mathtt{W(\&h2)}$ \\
05 $\mathtt{assert(A == 4);}$ \\
\hline
\end{tabular}
\end{center}
\caption{A feasible execution trace of the MPI program execution in \figref{fig:mpi_barrier}}
\label{fig:trace3}
\end{figure}

\figref{fig:trace3} shows what a feasible execution trace looks like. Each process waits on its barrier until it is matched with all other barriers. As a result, the message ``\texttt{Go}" and ``1" has no way to be sent out unless the message ``\texttt{4}" is received by process $0$ in variable $A$. Consequently, the assert on process $0$ does not fail. Compare the scenario in \figref{fig:mpi_barrier} with the one in \figref{fig:mpi}, it is easy to find out issuing barriers may change the way message delivers. The next section presents an algorithm that takes input as an MPI execution and a set of possible send-receive match pairs to encode both point-to-point and collective operation semantics into an SMT problem. It returns a satisfying assignment if message non-determinism is resolved in such a way that an assertion is violated (the assert is negated in the encoding); or it is unsatisfying if the execution is proved correct (meaning the user assertions hold on the given execution under all possible runtime behaviors). The encoding can be solved by an SMT solver such as Yices \cite{} or Z3 \cite{}.

%:TODO insert barriers in the program, how does the semantics change the outcoming execution.






